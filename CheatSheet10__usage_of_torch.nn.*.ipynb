{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このコードの目的\n",
    "\n",
    "少し複雑なネットワークをtensor.nnを使って簡単に定義する方法をまとめる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "Dim_input = 5\n",
    "Dim_output = 1\n",
    "\n",
    "# toy dataを作成する。\n",
    "# このデータは単純な線形結合では不可能でネットワークに工夫が必要\n",
    "x = torch.rand((N, Dim_input))\n",
    "y = 2 * x[:, 0] + 10 * x[:, 1] * x[:, 2]\n",
    "\n",
    "x_train, y_train = x[:900], y[:900]\n",
    "x_test, y_test = x[900:], y[900:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8912], grad_fn=<SelectBackward>) tensor(0.8997)\n",
      "tensor([6.3331], grad_fn=<SelectBackward>) tensor(5.8027)\n",
      "tensor([4.8072], grad_fn=<SelectBackward>) tensor(6.6585)\n",
      "tensor([2.7111], grad_fn=<SelectBackward>) tensor(2.7360)\n",
      "tensor([1.0591], grad_fn=<SelectBackward>) tensor(0.8989)\n",
      "tensor([4.9784], grad_fn=<SelectBackward>) tensor(6.1582)\n",
      "tensor([5.5727], grad_fn=<SelectBackward>) tensor(5.9645)\n",
      "tensor([3.5766], grad_fn=<SelectBackward>) tensor(2.5390)\n",
      "tensor([5.2392], grad_fn=<SelectBackward>) tensor(4.4531)\n",
      "tensor([2.4924], grad_fn=<SelectBackward>) tensor(2.3779)\n",
      "tensor([3.0132], grad_fn=<SelectBackward>) tensor(1.4361)\n",
      "tensor([6.4035], grad_fn=<SelectBackward>) tensor(8.0534)\n",
      "tensor([2.2899], grad_fn=<SelectBackward>) tensor(1.5370)\n",
      "tensor([6.7072], grad_fn=<SelectBackward>) tensor(8.3103)\n",
      "tensor([4.6894], grad_fn=<SelectBackward>) tensor(3.5375)\n",
      "tensor([2.2125], grad_fn=<SelectBackward>) tensor(2.0919)\n",
      "tensor([3.0127], grad_fn=<SelectBackward>) tensor(1.0422)\n",
      "tensor([0.3743], grad_fn=<SelectBackward>) tensor(0.4070)\n",
      "tensor([1.7316], grad_fn=<SelectBackward>) tensor(1.3496)\n",
      "tensor([1.9900], grad_fn=<SelectBackward>) tensor(0.8252)\n",
      "tensor([6.6211], grad_fn=<SelectBackward>) tensor(8.9842)\n",
      "tensor([0.9138], grad_fn=<SelectBackward>) tensor(0.6759)\n",
      "tensor([5.7216], grad_fn=<SelectBackward>) tensor(6.9482)\n",
      "tensor([2.9533], grad_fn=<SelectBackward>) tensor(1.5486)\n",
      "tensor([0.9358], grad_fn=<SelectBackward>) tensor(0.6620)\n",
      "tensor([4.0846], grad_fn=<SelectBackward>) tensor(2.3646)\n",
      "tensor([2.9041], grad_fn=<SelectBackward>) tensor(2.7509)\n",
      "tensor([1.7339], grad_fn=<SelectBackward>) tensor(1.0996)\n",
      "tensor([5.2158], grad_fn=<SelectBackward>) tensor(6.3467)\n",
      "tensor([3.7215], grad_fn=<SelectBackward>) tensor(3.1543)\n",
      "tensor([3.9757], grad_fn=<SelectBackward>) tensor(3.9305)\n",
      "tensor([4.9059], grad_fn=<SelectBackward>) tensor(5.5267)\n",
      "tensor([4.9936], grad_fn=<SelectBackward>) tensor(3.4172)\n",
      "tensor([5.0445], grad_fn=<SelectBackward>) tensor(5.9527)\n",
      "tensor([1.5766], grad_fn=<SelectBackward>) tensor(1.4833)\n",
      "tensor([4.6854], grad_fn=<SelectBackward>) tensor(5.6294)\n",
      "tensor([3.5078], grad_fn=<SelectBackward>) tensor(4.0856)\n",
      "tensor([2.3023], grad_fn=<SelectBackward>) tensor(1.5585)\n",
      "tensor([5.6688], grad_fn=<SelectBackward>) tensor(5.4686)\n",
      "tensor([2.7763], grad_fn=<SelectBackward>) tensor(3.0520)\n",
      "tensor([4.9906], grad_fn=<SelectBackward>) tensor(5.7602)\n",
      "tensor([3.4427], grad_fn=<SelectBackward>) tensor(3.0449)\n",
      "tensor([7.0326], grad_fn=<SelectBackward>) tensor(7.2316)\n",
      "tensor([2.8789], grad_fn=<SelectBackward>) tensor(2.6027)\n",
      "tensor([4.5591], grad_fn=<SelectBackward>) tensor(4.2364)\n",
      "tensor([4.3034], grad_fn=<SelectBackward>) tensor(5.0386)\n",
      "tensor([2.2174], grad_fn=<SelectBackward>) tensor(1.2926)\n",
      "tensor([3.9156], grad_fn=<SelectBackward>) tensor(3.7685)\n",
      "tensor([4.0603], grad_fn=<SelectBackward>) tensor(4.4685)\n",
      "tensor([3.8613], grad_fn=<SelectBackward>) tensor(3.5483)\n",
      "tensor([5.9977], grad_fn=<SelectBackward>) tensor(6.9347)\n",
      "tensor([2.6581], grad_fn=<SelectBackward>) tensor(2.2655)\n",
      "tensor([2.5788], grad_fn=<SelectBackward>) tensor(2.0384)\n",
      "tensor([1.8826], grad_fn=<SelectBackward>) tensor(0.6297)\n",
      "tensor([3.8015], grad_fn=<SelectBackward>) tensor(2.5072)\n",
      "tensor([6.4106], grad_fn=<SelectBackward>) tensor(7.4588)\n",
      "tensor([3.4472], grad_fn=<SelectBackward>) tensor(2.0137)\n",
      "tensor([3.1571], grad_fn=<SelectBackward>) tensor(2.9448)\n",
      "tensor([1.1559], grad_fn=<SelectBackward>) tensor(1.3164)\n",
      "tensor([3.4333], grad_fn=<SelectBackward>) tensor(3.1912)\n",
      "tensor([4.2766], grad_fn=<SelectBackward>) tensor(5.2787)\n",
      "tensor([7.7073], grad_fn=<SelectBackward>) tensor(9.3180)\n",
      "tensor([3.4762], grad_fn=<SelectBackward>) tensor(3.8105)\n",
      "tensor([4.4641], grad_fn=<SelectBackward>) tensor(4.1445)\n",
      "tensor([6.1848], grad_fn=<SelectBackward>) tensor(6.9697)\n",
      "tensor([3.0408], grad_fn=<SelectBackward>) tensor(1.9775)\n",
      "tensor([4.3022], grad_fn=<SelectBackward>) tensor(3.0782)\n",
      "tensor([5.4830], grad_fn=<SelectBackward>) tensor(4.8908)\n",
      "tensor([5.6376], grad_fn=<SelectBackward>) tensor(6.6249)\n",
      "tensor([2.4126], grad_fn=<SelectBackward>) tensor(1.3192)\n",
      "tensor([6.7498], grad_fn=<SelectBackward>) tensor(9.4042)\n",
      "tensor([5.9313], grad_fn=<SelectBackward>) tensor(4.5442)\n",
      "tensor([3.1591], grad_fn=<SelectBackward>) tensor(3.6589)\n",
      "tensor([6.3664], grad_fn=<SelectBackward>) tensor(8.5775)\n",
      "tensor([7.2771], grad_fn=<SelectBackward>) tensor(10.1993)\n",
      "tensor([4.7553], grad_fn=<SelectBackward>) tensor(5.3111)\n",
      "tensor([0.5439], grad_fn=<SelectBackward>) tensor(0.4138)\n",
      "tensor([3.5759], grad_fn=<SelectBackward>) tensor(3.7322)\n",
      "tensor([5.7216], grad_fn=<SelectBackward>) tensor(5.8214)\n",
      "tensor([3.1271], grad_fn=<SelectBackward>) tensor(1.1709)\n",
      "tensor([6.2977], grad_fn=<SelectBackward>) tensor(6.4044)\n",
      "tensor([2.6709], grad_fn=<SelectBackward>) tensor(0.9424)\n",
      "tensor([4.9274], grad_fn=<SelectBackward>) tensor(6.0675)\n",
      "tensor([2.0364], grad_fn=<SelectBackward>) tensor(2.2087)\n",
      "tensor([5.2584], grad_fn=<SelectBackward>) tensor(6.0134)\n",
      "tensor([0.4970], grad_fn=<SelectBackward>) tensor(0.4173)\n",
      "tensor([7.4540], grad_fn=<SelectBackward>) tensor(9.1046)\n",
      "tensor([2.9801], grad_fn=<SelectBackward>) tensor(2.2336)\n",
      "tensor([2.5659], grad_fn=<SelectBackward>) tensor(0.8047)\n",
      "tensor([4.2504], grad_fn=<SelectBackward>) tensor(1.7811)\n",
      "tensor([7.1242], grad_fn=<SelectBackward>) tensor(8.0329)\n",
      "tensor([4.4189], grad_fn=<SelectBackward>) tensor(4.5131)\n",
      "tensor([4.4128], grad_fn=<SelectBackward>) tensor(2.4592)\n",
      "tensor([6.6293], grad_fn=<SelectBackward>) tensor(6.9803)\n",
      "tensor([4.7983], grad_fn=<SelectBackward>) tensor(5.2373)\n",
      "tensor([0.5444], grad_fn=<SelectBackward>) tensor(0.5185)\n",
      "tensor([3.8587], grad_fn=<SelectBackward>) tensor(2.4248)\n",
      "tensor([3.1122], grad_fn=<SelectBackward>) tensor(2.3909)\n",
      "tensor([2.8282], grad_fn=<SelectBackward>) tensor(1.8798)\n",
      "tensor([2.6847], grad_fn=<SelectBackward>) tensor(2.1182)\n"
     ]
    }
   ],
   "source": [
    "# シンプルな解決法として、適切なactivation関数を設定した多層ネットワークを定義する\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(Dim_input,  10, bias=None),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10,  10, bias=None),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10,  Dim_output, bias=None),\n",
    "            )\n",
    "criterion = torch.nn.L1Loss(reduction='mean') \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "# 精度を最大化するために、batch_size=1で学習する。\n",
    "batch_size = 1\n",
    "epoch_size = 1000\n",
    "for t in range(epoch_size):\n",
    "    batch_indexes = random.choices(range(x_train.shape[0]), k=batch_size)\n",
    "    _x, _y = x_train[batch_indexes], y_train[batch_indexes]\n",
    "    loss = criterion(model(_x), _y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "# test_setで学習結果を確認する    \n",
    "for predict, answer in zip(model(x_test), y_test):\n",
    "    print(predict, answer)\n",
    "\n",
    "# ある程度は予測ができている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6429], grad_fn=<AddBackward0>) tensor(0.8997)\n",
      "tensor([5.7105], grad_fn=<AddBackward0>) tensor(5.8027)\n",
      "tensor([4.8730], grad_fn=<AddBackward0>) tensor(6.6585)\n",
      "tensor([2.8755], grad_fn=<AddBackward0>) tensor(2.7360)\n",
      "tensor([0.9719], grad_fn=<AddBackward0>) tensor(0.8989)\n",
      "tensor([4.8311], grad_fn=<AddBackward0>) tensor(6.1582)\n",
      "tensor([5.1129], grad_fn=<AddBackward0>) tensor(5.9645)\n",
      "tensor([3.2644], grad_fn=<AddBackward0>) tensor(2.5390)\n",
      "tensor([4.6793], grad_fn=<AddBackward0>) tensor(4.4531)\n",
      "tensor([2.4203], grad_fn=<AddBackward0>) tensor(2.3779)\n",
      "tensor([2.7729], grad_fn=<AddBackward0>) tensor(1.4361)\n",
      "tensor([6.2935], grad_fn=<AddBackward0>) tensor(8.0534)\n",
      "tensor([2.3044], grad_fn=<AddBackward0>) tensor(1.5370)\n",
      "tensor([6.3652], grad_fn=<AddBackward0>) tensor(8.3103)\n",
      "tensor([4.3283], grad_fn=<AddBackward0>) tensor(3.5375)\n",
      "tensor([1.8659], grad_fn=<AddBackward0>) tensor(2.0919)\n",
      "tensor([3.1242], grad_fn=<AddBackward0>) tensor(1.0422)\n",
      "tensor([0.1976], grad_fn=<AddBackward0>) tensor(0.4070)\n",
      "tensor([1.7363], grad_fn=<AddBackward0>) tensor(1.3496)\n",
      "tensor([1.7540], grad_fn=<AddBackward0>) tensor(0.8252)\n",
      "tensor([6.3339], grad_fn=<AddBackward0>) tensor(8.9842)\n",
      "tensor([0.8929], grad_fn=<AddBackward0>) tensor(0.6759)\n",
      "tensor([5.3306], grad_fn=<AddBackward0>) tensor(6.9482)\n",
      "tensor([3.0474], grad_fn=<AddBackward0>) tensor(1.5486)\n",
      "tensor([1.0370], grad_fn=<AddBackward0>) tensor(0.6620)\n",
      "tensor([4.0067], grad_fn=<AddBackward0>) tensor(2.3646)\n",
      "tensor([2.8287], grad_fn=<AddBackward0>) tensor(2.7509)\n",
      "tensor([1.6233], grad_fn=<AddBackward0>) tensor(1.0996)\n",
      "tensor([5.1380], grad_fn=<AddBackward0>) tensor(6.3467)\n",
      "tensor([3.6208], grad_fn=<AddBackward0>) tensor(3.1543)\n",
      "tensor([3.8469], grad_fn=<AddBackward0>) tensor(3.9305)\n",
      "tensor([4.7129], grad_fn=<AddBackward0>) tensor(5.5267)\n",
      "tensor([4.6060], grad_fn=<AddBackward0>) tensor(3.4172)\n",
      "tensor([4.8541], grad_fn=<AddBackward0>) tensor(5.9527)\n",
      "tensor([1.4425], grad_fn=<AddBackward0>) tensor(1.4833)\n",
      "tensor([4.6159], grad_fn=<AddBackward0>) tensor(5.6294)\n",
      "tensor([3.4470], grad_fn=<AddBackward0>) tensor(4.0856)\n",
      "tensor([2.2433], grad_fn=<AddBackward0>) tensor(1.5585)\n",
      "tensor([5.1164], grad_fn=<AddBackward0>) tensor(5.4686)\n",
      "tensor([2.6597], grad_fn=<AddBackward0>) tensor(3.0520)\n",
      "tensor([4.9805], grad_fn=<AddBackward0>) tensor(5.7602)\n",
      "tensor([3.3406], grad_fn=<AddBackward0>) tensor(3.0449)\n",
      "tensor([6.2776], grad_fn=<AddBackward0>) tensor(7.2316)\n",
      "tensor([3.1659], grad_fn=<AddBackward0>) tensor(2.6027)\n",
      "tensor([4.6298], grad_fn=<AddBackward0>) tensor(4.2364)\n",
      "tensor([4.2996], grad_fn=<AddBackward0>) tensor(5.0386)\n",
      "tensor([2.0596], grad_fn=<AddBackward0>) tensor(1.2926)\n",
      "tensor([4.0453], grad_fn=<AddBackward0>) tensor(3.7685)\n",
      "tensor([4.0438], grad_fn=<AddBackward0>) tensor(4.4685)\n",
      "tensor([3.9493], grad_fn=<AddBackward0>) tensor(3.5483)\n",
      "tensor([5.4491], grad_fn=<AddBackward0>) tensor(6.9347)\n",
      "tensor([2.9553], grad_fn=<AddBackward0>) tensor(2.2655)\n",
      "tensor([2.7392], grad_fn=<AddBackward0>) tensor(2.0384)\n",
      "tensor([1.9245], grad_fn=<AddBackward0>) tensor(0.6297)\n",
      "tensor([3.6477], grad_fn=<AddBackward0>) tensor(2.5072)\n",
      "tensor([5.9387], grad_fn=<AddBackward0>) tensor(7.4588)\n",
      "tensor([3.1038], grad_fn=<AddBackward0>) tensor(2.0137)\n",
      "tensor([3.1683], grad_fn=<AddBackward0>) tensor(2.9448)\n",
      "tensor([0.3477], grad_fn=<AddBackward0>) tensor(1.3164)\n",
      "tensor([3.4177], grad_fn=<AddBackward0>) tensor(3.1912)\n",
      "tensor([4.2605], grad_fn=<AddBackward0>) tensor(5.2787)\n",
      "tensor([6.9072], grad_fn=<AddBackward0>) tensor(9.3180)\n",
      "tensor([3.6591], grad_fn=<AddBackward0>) tensor(3.8105)\n",
      "tensor([4.3517], grad_fn=<AddBackward0>) tensor(4.1445)\n",
      "tensor([5.6644], grad_fn=<AddBackward0>) tensor(6.9697)\n",
      "tensor([3.1701], grad_fn=<AddBackward0>) tensor(1.9775)\n",
      "tensor([3.7676], grad_fn=<AddBackward0>) tensor(3.0782)\n",
      "tensor([5.0354], grad_fn=<AddBackward0>) tensor(4.8908)\n",
      "tensor([5.5921], grad_fn=<AddBackward0>) tensor(6.6249)\n",
      "tensor([2.4507], grad_fn=<AddBackward0>) tensor(1.3192)\n",
      "tensor([6.4106], grad_fn=<AddBackward0>) tensor(9.4042)\n",
      "tensor([5.3882], grad_fn=<AddBackward0>) tensor(4.5442)\n",
      "tensor([3.3083], grad_fn=<AddBackward0>) tensor(3.6589)\n",
      "tensor([5.9806], grad_fn=<AddBackward0>) tensor(8.5775)\n",
      "tensor([6.9818], grad_fn=<AddBackward0>) tensor(10.1993)\n",
      "tensor([4.6110], grad_fn=<AddBackward0>) tensor(5.3111)\n",
      "tensor([0.5277], grad_fn=<AddBackward0>) tensor(0.4138)\n",
      "tensor([3.5284], grad_fn=<AddBackward0>) tensor(3.7322)\n",
      "tensor([5.2210], grad_fn=<AddBackward0>) tensor(5.8214)\n",
      "tensor([3.0257], grad_fn=<AddBackward0>) tensor(1.1709)\n",
      "tensor([5.7623], grad_fn=<AddBackward0>) tensor(6.4044)\n",
      "tensor([2.8915], grad_fn=<AddBackward0>) tensor(0.9424)\n",
      "tensor([4.8568], grad_fn=<AddBackward0>) tensor(6.0675)\n",
      "tensor([2.0524], grad_fn=<AddBackward0>) tensor(2.2087)\n",
      "tensor([5.2405], grad_fn=<AddBackward0>) tensor(6.0134)\n",
      "tensor([0.4600], grad_fn=<AddBackward0>) tensor(0.4173)\n",
      "tensor([6.6968], grad_fn=<AddBackward0>) tensor(9.1046)\n",
      "tensor([2.8630], grad_fn=<AddBackward0>) tensor(2.2336)\n",
      "tensor([2.6255], grad_fn=<AddBackward0>) tensor(0.8047)\n",
      "tensor([4.0416], grad_fn=<AddBackward0>) tensor(1.7811)\n",
      "tensor([6.5147], grad_fn=<AddBackward0>) tensor(8.0329)\n",
      "tensor([4.0959], grad_fn=<AddBackward0>) tensor(4.5131)\n",
      "tensor([4.0027], grad_fn=<AddBackward0>) tensor(2.4592)\n",
      "tensor([5.9389], grad_fn=<AddBackward0>) tensor(6.9803)\n",
      "tensor([4.9155], grad_fn=<AddBackward0>) tensor(5.2373)\n",
      "tensor([0.1337], grad_fn=<AddBackward0>) tensor(0.5185)\n",
      "tensor([3.4565], grad_fn=<AddBackward0>) tensor(2.4248)\n",
      "tensor([3.2336], grad_fn=<AddBackward0>) tensor(2.3909)\n",
      "tensor([2.6924], grad_fn=<AddBackward0>) tensor(1.8798)\n",
      "tensor([2.6888], grad_fn=<AddBackward0>) tensor(2.1182)\n"
     ]
    }
   ],
   "source": [
    "# toy data の生成モデルに等しいネットワーク構成になるようにmodelを組み合わせてみる。\n",
    "\n",
    "simple_linear_model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(Dim_input,  Dim_output, bias=None),\n",
    "            )\n",
    "linear_cross_section_model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(Dim_input,  1, bias=None),\n",
    "            )\n",
    "\n",
    "criterion = torch.nn.L1Loss(reduction='mean') \n",
    "optimizer = torch.optim.Adam(\n",
    "                            [\n",
    "                                {'params':simple_linear_model.parameters()}, \n",
    "                                {'params':linear_cross_section_model.parameters()}\n",
    "                            ]\n",
    "                             , lr=0.01, weight_decay=0.01\n",
    "            )\n",
    "\n",
    "# 精度を最大化するために、batch_size=1で学習する。\n",
    "batch_size = 1\n",
    "epoch_size = 1000\n",
    "for t in range(epoch_size):\n",
    "    batch_indexes = random.choices(range(x_train.shape[0]), k=batch_size)\n",
    "    _x, _y = x_train[batch_indexes], y_train[batch_indexes]\n",
    "    _y_pre = simple_linear_model(_x) + linear_cross_section_model(_x)\n",
    "    loss = criterion(_y_pre, _y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "# test_setで学習結果を確認する    \n",
    "for _x, answer in zip(x_test, y_test):\n",
    "    predict = simple_linear_model(_x) + linear_cross_section_model(_x)\n",
    "    print(predict, answer)\n",
    "\n",
    "# ある程度は予測ができている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
