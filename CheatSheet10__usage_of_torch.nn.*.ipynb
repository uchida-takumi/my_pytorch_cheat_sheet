{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このコードの目的\n",
    "\n",
    "少し複雑なネットワークをtensor.nnを使って簡単に定義する方法をまとめる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "Dim_input = 5\n",
    "Dim_output = 1\n",
    "\n",
    "# toy dataを作成する。\n",
    "# このデータは単純な線形結合では不可能でネットワークに工夫が必要\n",
    "x = torch.rand((N, Dim_input))\n",
    "y = 2 * x[:, 0] + 10 * x[:, 1] * x[:, 2]\n",
    "\n",
    "x_train, y_train = x[:900], y[:900]\n",
    "x_test, y_test = x[900:], y[900:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6294], grad_fn=<SelectBackward>) tensor(2.3237)\n",
      "tensor([1.8704], grad_fn=<SelectBackward>) tensor(2.0627)\n",
      "tensor([2.5402], grad_fn=<SelectBackward>) tensor(1.8409)\n",
      "tensor([2.1154], grad_fn=<SelectBackward>) tensor(2.1281)\n",
      "tensor([1.5560], grad_fn=<SelectBackward>) tensor(1.4000)\n",
      "tensor([5.3299], grad_fn=<SelectBackward>) tensor(7.2199)\n",
      "tensor([0.6620], grad_fn=<SelectBackward>) tensor(0.9226)\n",
      "tensor([5.4018], grad_fn=<SelectBackward>) tensor(6.9417)\n",
      "tensor([2.6014], grad_fn=<SelectBackward>) tensor(2.0194)\n",
      "tensor([1.5304], grad_fn=<SelectBackward>) tensor(1.3788)\n",
      "tensor([4.3046], grad_fn=<SelectBackward>) tensor(4.1710)\n",
      "tensor([2.5456], grad_fn=<SelectBackward>) tensor(1.2071)\n",
      "tensor([3.4212], grad_fn=<SelectBackward>) tensor(2.8320)\n",
      "tensor([3.4133], grad_fn=<SelectBackward>) tensor(2.2928)\n",
      "tensor([1.6176], grad_fn=<SelectBackward>) tensor(0.4282)\n",
      "tensor([2.0417], grad_fn=<SelectBackward>) tensor(1.7778)\n",
      "tensor([6.3570], grad_fn=<SelectBackward>) tensor(8.3319)\n",
      "tensor([3.2468], grad_fn=<SelectBackward>) tensor(2.5599)\n",
      "tensor([0.9409], grad_fn=<SelectBackward>) tensor(0.3050)\n",
      "tensor([4.2675], grad_fn=<SelectBackward>) tensor(4.2213)\n",
      "tensor([3.2437], grad_fn=<SelectBackward>) tensor(2.3214)\n",
      "tensor([1.0314], grad_fn=<SelectBackward>) tensor(1.0850)\n",
      "tensor([3.1316], grad_fn=<SelectBackward>) tensor(1.9475)\n",
      "tensor([3.5231], grad_fn=<SelectBackward>) tensor(3.0481)\n",
      "tensor([2.6663], grad_fn=<SelectBackward>) tensor(1.7501)\n",
      "tensor([4.1100], grad_fn=<SelectBackward>) tensor(4.6693)\n",
      "tensor([1.3036], grad_fn=<SelectBackward>) tensor(0.5433)\n",
      "tensor([1.3155], grad_fn=<SelectBackward>) tensor(1.7908)\n",
      "tensor([6.2099], grad_fn=<SelectBackward>) tensor(9.3114)\n",
      "tensor([3.0391], grad_fn=<SelectBackward>) tensor(2.7420)\n",
      "tensor([2.0363], grad_fn=<SelectBackward>) tensor(1.1990)\n",
      "tensor([3.1385], grad_fn=<SelectBackward>) tensor(3.5684)\n",
      "tensor([5.7846], grad_fn=<SelectBackward>) tensor(8.1111)\n",
      "tensor([2.8413], grad_fn=<SelectBackward>) tensor(2.4776)\n",
      "tensor([3.4965], grad_fn=<SelectBackward>) tensor(4.2163)\n",
      "tensor([5.6760], grad_fn=<SelectBackward>) tensor(9.0999)\n",
      "tensor([5.0074], grad_fn=<SelectBackward>) tensor(6.4707)\n",
      "tensor([4.6681], grad_fn=<SelectBackward>) tensor(4.8177)\n",
      "tensor([2.9427], grad_fn=<SelectBackward>) tensor(1.1897)\n",
      "tensor([4.9838], grad_fn=<SelectBackward>) tensor(6.5430)\n",
      "tensor([2.8149], grad_fn=<SelectBackward>) tensor(0.8153)\n",
      "tensor([0.8937], grad_fn=<SelectBackward>) tensor(0.7715)\n",
      "tensor([3.4403], grad_fn=<SelectBackward>) tensor(3.4458)\n",
      "tensor([5.8840], grad_fn=<SelectBackward>) tensor(7.6287)\n",
      "tensor([4.1170], grad_fn=<SelectBackward>) tensor(3.5092)\n",
      "tensor([3.3222], grad_fn=<SelectBackward>) tensor(2.0955)\n",
      "tensor([5.2946], grad_fn=<SelectBackward>) tensor(7.0567)\n",
      "tensor([3.7990], grad_fn=<SelectBackward>) tensor(4.1138)\n",
      "tensor([2.8294], grad_fn=<SelectBackward>) tensor(2.6334)\n",
      "tensor([1.8432], grad_fn=<SelectBackward>) tensor(0.9314)\n",
      "tensor([4.8567], grad_fn=<SelectBackward>) tensor(6.2741)\n",
      "tensor([1.7884], grad_fn=<SelectBackward>) tensor(2.0013)\n",
      "tensor([4.4972], grad_fn=<SelectBackward>) tensor(4.4114)\n",
      "tensor([1.7809], grad_fn=<SelectBackward>) tensor(1.6090)\n",
      "tensor([4.2222], grad_fn=<SelectBackward>) tensor(3.8590)\n",
      "tensor([2.8877], grad_fn=<SelectBackward>) tensor(1.8218)\n",
      "tensor([2.3471], grad_fn=<SelectBackward>) tensor(1.3587)\n",
      "tensor([1.7912], grad_fn=<SelectBackward>) tensor(0.6898)\n",
      "tensor([3.1791], grad_fn=<SelectBackward>) tensor(2.7803)\n",
      "tensor([1.9525], grad_fn=<SelectBackward>) tensor(1.7510)\n",
      "tensor([3.6922], grad_fn=<SelectBackward>) tensor(4.3467)\n",
      "tensor([1.7713], grad_fn=<SelectBackward>) tensor(1.6835)\n",
      "tensor([3.4946], grad_fn=<SelectBackward>) tensor(2.8245)\n",
      "tensor([4.0326], grad_fn=<SelectBackward>) tensor(4.6564)\n",
      "tensor([0.8284], grad_fn=<SelectBackward>) tensor(1.2467)\n",
      "tensor([2.4046], grad_fn=<SelectBackward>) tensor(1.2569)\n",
      "tensor([3.1040], grad_fn=<SelectBackward>) tensor(2.2006)\n",
      "tensor([4.5200], grad_fn=<SelectBackward>) tensor(4.2163)\n",
      "tensor([4.0719], grad_fn=<SelectBackward>) tensor(4.1892)\n",
      "tensor([1.6886], grad_fn=<SelectBackward>) tensor(1.6078)\n",
      "tensor([2.9872], grad_fn=<SelectBackward>) tensor(2.8849)\n",
      "tensor([3.4301], grad_fn=<SelectBackward>) tensor(3.5457)\n",
      "tensor([2.0204], grad_fn=<SelectBackward>) tensor(1.3300)\n",
      "tensor([4.5038], grad_fn=<SelectBackward>) tensor(5.3524)\n",
      "tensor([3.9667], grad_fn=<SelectBackward>) tensor(4.6417)\n",
      "tensor([3.7976], grad_fn=<SelectBackward>) tensor(2.7675)\n",
      "tensor([6.5386], grad_fn=<SelectBackward>) tensor(9.9653)\n",
      "tensor([4.6090], grad_fn=<SelectBackward>) tensor(3.9852)\n",
      "tensor([5.0534], grad_fn=<SelectBackward>) tensor(6.0888)\n",
      "tensor([3.1765], grad_fn=<SelectBackward>) tensor(3.1076)\n",
      "tensor([3.0212], grad_fn=<SelectBackward>) tensor(2.1195)\n",
      "tensor([4.1397], grad_fn=<SelectBackward>) tensor(4.4416)\n",
      "tensor([4.1687], grad_fn=<SelectBackward>) tensor(5.0003)\n",
      "tensor([2.6803], grad_fn=<SelectBackward>) tensor(2.4756)\n",
      "tensor([0.8829], grad_fn=<SelectBackward>) tensor(0.8102)\n",
      "tensor([3.3158], grad_fn=<SelectBackward>) tensor(2.7365)\n",
      "tensor([2.0546], grad_fn=<SelectBackward>) tensor(1.1078)\n",
      "tensor([5.6305], grad_fn=<SelectBackward>) tensor(6.9276)\n",
      "tensor([4.4174], grad_fn=<SelectBackward>) tensor(5.5749)\n",
      "tensor([1.7608], grad_fn=<SelectBackward>) tensor(1.5255)\n",
      "tensor([5.0899], grad_fn=<SelectBackward>) tensor(6.0106)\n",
      "tensor([1.3102], grad_fn=<SelectBackward>) tensor(1.4408)\n",
      "tensor([5.3429], grad_fn=<SelectBackward>) tensor(7.0372)\n",
      "tensor([2.2068], grad_fn=<SelectBackward>) tensor(2.1627)\n",
      "tensor([3.9370], grad_fn=<SelectBackward>) tensor(4.0813)\n",
      "tensor([3.5796], grad_fn=<SelectBackward>) tensor(3.4832)\n",
      "tensor([4.9739], grad_fn=<SelectBackward>) tensor(5.9828)\n",
      "tensor([2.9827], grad_fn=<SelectBackward>) tensor(2.6779)\n",
      "tensor([2.9264], grad_fn=<SelectBackward>) tensor(2.0376)\n",
      "tensor([4.4426], grad_fn=<SelectBackward>) tensor(4.8172)\n"
     ]
    }
   ],
   "source": [
    "# シンプルな解決法として、適切なactivation関数を設定した多層ネットワークを定義する\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(Dim_input,  10, bias=None),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10,  10, bias=None),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10,  Dim_output, bias=None),\n",
    "            )\n",
    "criterion = torch.nn.L1Loss(reduction='mean') \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "# 精度を最大化するために、batch_size=1で学習する。\n",
    "batch_size = 1\n",
    "epoch_size = 1000\n",
    "for t in range(epoch_size):\n",
    "    batch_indexes = random.choices(range(x_train.shape[0]), k=batch_size)\n",
    "    _x, _y = x_train[batch_indexes], y_train[batch_indexes]\n",
    "    loss = criterion(model(_x), _y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "# test_setで学習結果を確認する    \n",
    "for predict, answer in zip(model(x_test), y_test):\n",
    "    print(predict, answer)\n",
    "\n",
    "# ある程度は予測ができている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4711], grad_fn=<AddBackward0>) tensor(2.3237)\n",
      "tensor([1.5897], grad_fn=<AddBackward0>) tensor(2.0627)\n",
      "tensor([2.2987], grad_fn=<AddBackward0>) tensor(1.8409)\n",
      "tensor([2.0295], grad_fn=<AddBackward0>) tensor(2.1281)\n",
      "tensor([1.4096], grad_fn=<AddBackward0>) tensor(1.4000)\n",
      "tensor([5.0768], grad_fn=<AddBackward0>) tensor(7.2199)\n",
      "tensor([0.5334], grad_fn=<AddBackward0>) tensor(0.9226)\n",
      "tensor([5.0669], grad_fn=<AddBackward0>) tensor(6.9417)\n",
      "tensor([2.4485], grad_fn=<AddBackward0>) tensor(2.0194)\n",
      "tensor([1.2300], grad_fn=<AddBackward0>) tensor(1.3788)\n",
      "tensor([3.9665], grad_fn=<AddBackward0>) tensor(4.1710)\n",
      "tensor([2.6057], grad_fn=<AddBackward0>) tensor(1.2071)\n",
      "tensor([3.1805], grad_fn=<AddBackward0>) tensor(2.8320)\n",
      "tensor([3.1861], grad_fn=<AddBackward0>) tensor(2.2928)\n",
      "tensor([1.4144], grad_fn=<AddBackward0>) tensor(0.4282)\n",
      "tensor([1.8500], grad_fn=<AddBackward0>) tensor(1.7778)\n",
      "tensor([6.0645], grad_fn=<AddBackward0>) tensor(8.3319)\n",
      "tensor([3.0600], grad_fn=<AddBackward0>) tensor(2.5599)\n",
      "tensor([0.7442], grad_fn=<AddBackward0>) tensor(0.3050)\n",
      "tensor([4.2067], grad_fn=<AddBackward0>) tensor(4.2213)\n",
      "tensor([3.1535], grad_fn=<AddBackward0>) tensor(2.3214)\n",
      "tensor([0.8560], grad_fn=<AddBackward0>) tensor(1.0850)\n",
      "tensor([2.9855], grad_fn=<AddBackward0>) tensor(1.9475)\n",
      "tensor([3.3871], grad_fn=<AddBackward0>) tensor(3.0481)\n",
      "tensor([2.7587], grad_fn=<AddBackward0>) tensor(1.7501)\n",
      "tensor([3.9453], grad_fn=<AddBackward0>) tensor(4.6693)\n",
      "tensor([1.2711], grad_fn=<AddBackward0>) tensor(0.5433)\n",
      "tensor([1.0842], grad_fn=<AddBackward0>) tensor(1.7908)\n",
      "tensor([5.8815], grad_fn=<AddBackward0>) tensor(9.3114)\n",
      "tensor([3.0203], grad_fn=<AddBackward0>) tensor(2.7420)\n",
      "tensor([1.9139], grad_fn=<AddBackward0>) tensor(1.1990)\n",
      "tensor([2.8503], grad_fn=<AddBackward0>) tensor(3.5684)\n",
      "tensor([5.3886], grad_fn=<AddBackward0>) tensor(8.1111)\n",
      "tensor([2.7119], grad_fn=<AddBackward0>) tensor(2.4776)\n",
      "tensor([3.1531], grad_fn=<AddBackward0>) tensor(4.2163)\n",
      "tensor([5.1945], grad_fn=<AddBackward0>) tensor(9.0999)\n",
      "tensor([4.6215], grad_fn=<AddBackward0>) tensor(6.4707)\n",
      "tensor([4.4072], grad_fn=<AddBackward0>) tensor(4.8177)\n",
      "tensor([3.0431], grad_fn=<AddBackward0>) tensor(1.1897)\n",
      "tensor([4.6077], grad_fn=<AddBackward0>) tensor(6.5430)\n",
      "tensor([3.0097], grad_fn=<AddBackward0>) tensor(0.8153)\n",
      "tensor([0.7879], grad_fn=<AddBackward0>) tensor(0.7715)\n",
      "tensor([3.2900], grad_fn=<AddBackward0>) tensor(3.4458)\n",
      "tensor([5.7361], grad_fn=<AddBackward0>) tensor(7.6287)\n",
      "tensor([3.7449], grad_fn=<AddBackward0>) tensor(3.5092)\n",
      "tensor([3.0415], grad_fn=<AddBackward0>) tensor(2.0955)\n",
      "tensor([4.9754], grad_fn=<AddBackward0>) tensor(7.0567)\n",
      "tensor([3.5144], grad_fn=<AddBackward0>) tensor(4.1138)\n",
      "tensor([2.6083], grad_fn=<AddBackward0>) tensor(2.6334)\n",
      "tensor([1.6981], grad_fn=<AddBackward0>) tensor(0.9314)\n",
      "tensor([4.5330], grad_fn=<AddBackward0>) tensor(6.2741)\n",
      "tensor([1.5068], grad_fn=<AddBackward0>) tensor(2.0013)\n",
      "tensor([4.1393], grad_fn=<AddBackward0>) tensor(4.4114)\n",
      "tensor([1.7353], grad_fn=<AddBackward0>) tensor(1.6090)\n",
      "tensor([4.1541], grad_fn=<AddBackward0>) tensor(3.8590)\n",
      "tensor([2.7902], grad_fn=<AddBackward0>) tensor(1.8218)\n",
      "tensor([2.4105], grad_fn=<AddBackward0>) tensor(1.3587)\n",
      "tensor([1.7551], grad_fn=<AddBackward0>) tensor(0.6898)\n",
      "tensor([3.0277], grad_fn=<AddBackward0>) tensor(2.7803)\n",
      "tensor([1.8149], grad_fn=<AddBackward0>) tensor(1.7510)\n",
      "tensor([3.3094], grad_fn=<AddBackward0>) tensor(4.3467)\n",
      "tensor([1.6371], grad_fn=<AddBackward0>) tensor(1.6835)\n",
      "tensor([3.3939], grad_fn=<AddBackward0>) tensor(2.8245)\n",
      "tensor([3.7465], grad_fn=<AddBackward0>) tensor(4.6564)\n",
      "tensor([0.4062], grad_fn=<AddBackward0>) tensor(1.2467)\n",
      "tensor([2.4709], grad_fn=<AddBackward0>) tensor(1.2569)\n",
      "tensor([2.9889], grad_fn=<AddBackward0>) tensor(2.2006)\n",
      "tensor([4.1973], grad_fn=<AddBackward0>) tensor(4.2163)\n",
      "tensor([3.8405], grad_fn=<AddBackward0>) tensor(4.1892)\n",
      "tensor([1.4170], grad_fn=<AddBackward0>) tensor(1.6078)\n",
      "tensor([2.6204], grad_fn=<AddBackward0>) tensor(2.8849)\n",
      "tensor([3.1364], grad_fn=<AddBackward0>) tensor(3.5457)\n",
      "tensor([2.0158], grad_fn=<AddBackward0>) tensor(1.3300)\n",
      "tensor([4.2376], grad_fn=<AddBackward0>) tensor(5.3524)\n",
      "tensor([3.6030], grad_fn=<AddBackward0>) tensor(4.6417)\n",
      "tensor([3.8005], grad_fn=<AddBackward0>) tensor(2.7675)\n",
      "tensor([6.1382], grad_fn=<AddBackward0>) tensor(9.9653)\n",
      "tensor([4.3428], grad_fn=<AddBackward0>) tensor(3.9852)\n",
      "tensor([4.9185], grad_fn=<AddBackward0>) tensor(6.0888)\n",
      "tensor([3.0337], grad_fn=<AddBackward0>) tensor(3.1076)\n",
      "tensor([2.7408], grad_fn=<AddBackward0>) tensor(2.1195)\n",
      "tensor([3.9616], grad_fn=<AddBackward0>) tensor(4.4416)\n",
      "tensor([3.7459], grad_fn=<AddBackward0>) tensor(5.0003)\n",
      "tensor([2.5162], grad_fn=<AddBackward0>) tensor(2.4756)\n",
      "tensor([0.2605], grad_fn=<AddBackward0>) tensor(0.8102)\n",
      "tensor([3.2595], grad_fn=<AddBackward0>) tensor(2.7365)\n",
      "tensor([2.2588], grad_fn=<AddBackward0>) tensor(1.1078)\n",
      "tensor([5.2946], grad_fn=<AddBackward0>) tensor(6.9276)\n",
      "tensor([4.0132], grad_fn=<AddBackward0>) tensor(5.5749)\n",
      "tensor([1.4583], grad_fn=<AddBackward0>) tensor(1.5255)\n",
      "tensor([4.8172], grad_fn=<AddBackward0>) tensor(6.0106)\n",
      "tensor([1.1652], grad_fn=<AddBackward0>) tensor(1.4408)\n",
      "tensor([5.1412], grad_fn=<AddBackward0>) tensor(7.0372)\n",
      "tensor([2.1579], grad_fn=<AddBackward0>) tensor(2.1627)\n",
      "tensor([3.6733], grad_fn=<AddBackward0>) tensor(4.0813)\n",
      "tensor([3.3915], grad_fn=<AddBackward0>) tensor(3.4832)\n",
      "tensor([4.6657], grad_fn=<AddBackward0>) tensor(5.9828)\n",
      "tensor([2.9220], grad_fn=<AddBackward0>) tensor(2.6779)\n",
      "tensor([2.8362], grad_fn=<AddBackward0>) tensor(2.0376)\n",
      "tensor([4.2860], grad_fn=<AddBackward0>) tensor(4.8172)\n"
     ]
    }
   ],
   "source": [
    "# toy data の生成モデルに等しいネットワーク構成になるようにmodelを組み合わせてみる。\n",
    "\n",
    "simple_linear_model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(Dim_input,  Dim_output, bias=None),\n",
    "            )\n",
    "linear_cross_section_model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(Dim_input,  1, bias=None),\n",
    "            )\n",
    "\n",
    "criterion = torch.nn.L1Loss(reduction='mean') \n",
    "optimizer = torch.optim.Adam(\n",
    "                            [\n",
    "                                {'params':simple_linear_model.parameters()}, \n",
    "                                {'params':linear_cross_section_model.parameters()}\n",
    "                            ]\n",
    "                             , lr=0.01, weight_decay=0.01\n",
    "            )\n",
    "\n",
    "# 精度を最大化するために、batch_size=1で学習する。\n",
    "batch_size = 1\n",
    "epoch_size = 1000\n",
    "for t in range(epoch_size):\n",
    "    batch_indexes = random.choices(range(x_train.shape[0]), k=batch_size)\n",
    "    _x, _y = x_train[batch_indexes], y_train[batch_indexes]\n",
    "    _y_pre = simple_linear_model(_x) + linear_cross_section_model(_x)\n",
    "    loss = criterion(_y_pre, _y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "# test_setで学習結果を確認する    \n",
    "for _x, answer in zip(x_test, y_test):\n",
    "    predict = simple_linear_model(_x) + linear_cross_section_model(_x)\n",
    "    print(predict, answer)\n",
    "\n",
    "# ある程度は予測ができている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
